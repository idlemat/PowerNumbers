\documentclass[acmsmall]{acmart}

\usepackage{algorithm2e}
\usepackage{amsthm}

\usepackage{todonotes}
\newcommand{\sotodo}{\todo[color=green]}
\newcommand{\sotodoinline}{\todo[color=green,inline=true]}



\AtBeginDocument{%
	\providecommand\BibTeX{{%
			\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\begin{document}
	
\title{PowerNumbers.jl: a fast approach to automatic asymptotics}

\author{Sheehan Olver}
\email{s.olver@imperial.ac.uk}
\affiliation{%
	\institution{Imperial College}
	\city{London}
	\state{England}
	\postcode{SW7 2AZ}
}

\author{Matthew Rees}
\email{matthew.rees.16@ucl.ac.uk}
\affiliation{%
	\institution{University College London}
	\city{London}
	\state{England}
	\postcode{WC1E 6BT}
}

\begin{abstract}
	We develop a scheme for quick arithmetic on asymptotic series, evaluated to just one or two terms. This generalizes the concept of dual numbers in automatic differentiation to support general algebraic powers, including negative powers to capture behaviour at infinity.  We give a full description of the algebraic rules for these newly defined {\it power numbers}, with justification of guaranteed equivalence to asymptotic algebra. Some example applications follow, including evaluation of complicated rational functions at infinity defined in terms of linear algebra, hypergeometric functions, and Stieltjes transforms over intervals for functions with power-like singularities and the endpoints.
\end{abstract}

\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10002950.10003705.10003707</concept_id>
	<concept_desc>Mathematics of computing~Solvers</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Mathematics of computing~Solvers}

\keywords{none}

\maketitle

\section{Introduction}

Asymptotic expansions are important computational tools in applied mathematics, that can reduce complicated functions to simple forms with specified accuracy. 


{\it Dual numbers} are a simpleÂ algebraic structure that underlies forward mode automatic-differentiation, with a convenient representation in terms of $2 \times 2$ matrices:

\begin{definition}
Let $K$ be a field. The set of matrices
$$\mathbf{D}^K = \left\{\begin{pmatrix}a & b \\ 0 & a \end{pmatrix} : a,b \in K\right\}$$ 
are called the set of \textbf{dual numbers}. The elements are typically denoted by
$$
a + b \epsilon \qquad \hbox{where} \qquad \epsilon = \begin{pmatrix} 0 & 1 \\ & 0 \end{pmatrix}.
$$
\end{definition}

The property that $\epsilon^2 = 0 $ suffices to guarante that general analytic matrix functions applied to dual numbers encode the derivative at the point $a$, namely:
$$
f(a + b \epsilon) = f(a) + b f'(b) \epsilon
$$
Thus any 

%are an algebraic structure whose elements take the form of
%$$
%a + b \epsilon
%$$
%where $a,b$ are elements of a field and $\epsilon$ follows the rule $\epsilon^2 = 0$.  
%
%

\section{Description}
\sotodoinline{$\mathbf{PN}^K$ shouldn't depend on $\epsilon$ as a paramter}
\begin{definition}
Let $K$ be a field. The set of functions of $\epsilon \in [0,\infty)$,
$$\mathbf{PN}^K_\epsilon = \{a\epsilon^\alpha + b\epsilon^\beta : a,b \in K;\alpha,\beta\in\mathbb{R}\cup\{\infty\}; \alpha\leq\beta\}$$ 
is called the set of \textbf{power numbers}. 
\end{definition}
In the case $\alpha=\beta$, we write only one term $(a+b)\epsilon^\beta$. Notationally, $\epsilon^0$ is omitted.
We enforce the equality $0\epsilon^\alpha + b\epsilon^\beta = b\epsilon^\beta$. However, in general, $a\epsilon^\alpha + 0\epsilon^\beta \neq a\epsilon^\alpha$.
By defining $(+,*)$ below, we acquire the double monoid $$\mathbb{PN}^K_\epsilon = (\mathbf{PN}^K_\epsilon,+,*)$$

\subsection{Basic Operations}
\begin{definition}
\textbf{Addition} $+:\mathbf{PN}^K_\epsilon \times \mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ is described by an algorithm.

\begin{algorithm}[H]
	\SetAlgoLined
	\KwData{$a\epsilon^\alpha + b\epsilon^\beta, c\epsilon^\gamma + d\epsilon^\delta \in \mathbf{PN}^K_\epsilon$; assume WLOG that $\beta \leq \delta$}
	\KwResult{$(a\epsilon^\alpha + b\epsilon^\beta) + (c\epsilon^\gamma + d\epsilon^\delta) = p\epsilon^\zeta + q\epsilon^\eta \in \mathbf{PN}^K_\epsilon$}
	\uIf{$\beta=\delta$}{
		\uIf{$\gamma=\beta$}{
			$p = a$, $q = b + c + d$, $\zeta = \alpha$, $\eta = \beta$
		}
		\uElseIf{$\alpha<\gamma<\beta$}{
			$p = a$, $q = c$, $\zeta = \alpha$, $\eta = \gamma$
		}
		\uElseIf{$\gamma=\alpha$}{
			$p = a + c$, $q = b + d$, $\zeta = \alpha$, $\eta = \beta$
		}
		\Else{
			$p = c$, $q = a$, $\zeta = \gamma$, $\eta = \alpha$
		}
	}
	\Else{
		\uIf{$\beta<\gamma$}{
			$p = a$, $q = b$, $\zeta = \alpha$, $\eta = \beta$
		}
		\uElseIf{$\gamma=\beta$}{
			$p = a$, $q = b + c$, $\zeta = \alpha$, $\eta = \beta$
		}
		\uElseIf{$\alpha<\gamma<\beta$}{
			$p = a$, $q = c$, $\zeta = \alpha$, $\eta = \gamma$
		}
		\uElseIf{$\gamma=\alpha$}{
			$p = a + c$, $q = b$, $\zeta = \alpha$, $\eta = \beta$
		}
		\Else{
			$p = c$, $q = a$, $\zeta = \gamma$, $\eta = \alpha$
		}
	}
	
	\caption{Summing Power Numbers}	
\end{algorithm}

The additive identity for Power Numbers is $0\epsilon^\infty$.
\end{definition}

\begin{definition}
\textbf{Multiplication} $*:\mathbf{PN}^K_\epsilon \times \mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ can be most simply expressed as addition of Power Numbers:
\begin{displaymath}
(a\epsilon^\alpha + b\epsilon^\beta) * (c\epsilon^\gamma + d\epsilon^\delta)
= (ac\epsilon^{\alpha+\gamma} + ad\epsilon^{\alpha+\delta}) + (bc\epsilon^{\beta+\gamma}+ bd\epsilon^{\beta+\delta})
= p\epsilon^\zeta + q\epsilon^\eta \in \mathbf{PN}^K_\epsilon
\end{displaymath}

The multiplicative identity for Power Numbers is $1 + 0\epsilon^\infty$.
\end{definition}
	

While $\mathbb{PN}^K_\epsilon$ is a monoid under both addition and multiplication, we can define two operations that have some of the properties we expect for subtraction and division. \\

\begin{definition} 
\textbf{Subtraction} $-:\mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ is defined as:
$$-(a\epsilon^\alpha + b\epsilon^\beta) = (-a)\epsilon^\alpha + (-b)\epsilon^\beta$$
Naturally, $-:\mathbf{PN}^K_\epsilon \times \mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ is defined as $A + (-(B))$, where $A, B \in \mathbf{PN}^K_\epsilon$.
\end{definition}

\begin{definition}
The \textbf{multiplicative pseudo-inverse} $inv:\mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ is slightly more complicated.

\begin{algorithm}[H]
	\SetAlgoLined
	\KwData{$a\epsilon^\alpha + b\epsilon^\beta \in \mathbf{PN}^K_\epsilon$}
	\KwResult{$$\frac{1}{a\epsilon^\alpha + b\epsilon^\beta} = p\epsilon^\zeta + q\epsilon^\eta \in \mathbf{PN}^K_\epsilon$$}
	\uIf{$\alpha=\infty$}{
		Not defined.
	}
	\uElseIf{$\alpha=\beta$}{
		$p = 0$, $q = \frac{1}{a+b}$, $\zeta = -\alpha$, $\eta = -\alpha$
	}
	\Else{
		$p = \frac{1}{a+b}$, $q = -\frac{b}{a^2}$, $\zeta = -\alpha$, $\eta = \beta-2\alpha$
	}
	
	\caption{Multiplicative Inversion}	
\end{algorithm}

\textbf{Division} $\div:\mathbf{PN}^K_\epsilon \times \mathbf{PN}^K_\epsilon \rightarrow \mathbf{PN}^K_\epsilon$ is defined as $A \div B = A * (inv(B))$, where $A, B \in \mathbf{PN}^K_\epsilon$.
\end{definition}

This matches the Dual Numbers case, where $\alpha = 0$, $\beta = 1$.

There is a special case wherein the pseudo-negative and -inverse are the true negative and inverse, which motivates the following
\begin{proposition}
For $A = a\epsilon^\alpha + b\epsilon^\beta \in \mathbf{PN}^K_\epsilon$, we have that $A-A=0\epsilon^\infty$ and $A \div A = 1 + 0\epsilon^\infty$ if and only if $\beta = \infty$.
\end{proposition}

\subsection{Exponentiation, Analytic Functions \& Asymptotic Series}

The definition of $A^m$ for $A \in \mathbf{PN}^K_\epsilon$, $m \in \mathbb{Z}$ follows naturally from the above definitions of multiplication and division. \\
Since we will generally consider $\epsilon$ to be small, we can extend any analytic function $h:K \rightarrow K$ to $h:\mathbf{PN}^K_{\epsilon} \rightarrow \mathbf{PN}^K_{\epsilon}$ for $\alpha \geq 0$. This is via Taylor series:

$$h(a\epsilon^0+b\epsilon^\beta) = h(a+b\epsilon^\beta) = h(a) + b\epsilon^\beta h'(a) \quad$$
$$h(a\epsilon^\alpha+b\epsilon^\beta) = h(0) + a\epsilon^\alpha h'(0) \quad where \quad \alpha \neq 0$$

Now, consider an asymptotic series that is also a Hahn series; that is,
\begin{equation}
S(z) = \sum_{n=1}^{\infty}a_nz^{\alpha_n} \quad as \quad z \rightarrow 0
\end{equation}
where the $\alpha_n \in \mathbb{R}$ are strictly increasing.
The primary significance of Power Numbers comes from the following 
\begin{proposition}
	Let $f(z) = az^\alpha + bz^\beta + o(z^\beta)$,	$g(z) = cz^\gamma + dz^\delta + o(z^\delta)$ be series of the form in $(1)$.
	Define the associated Power Numbers, $F = a\epsilon^\alpha + b\epsilon^\beta$, $G = c\epsilon^\gamma + d\epsilon^\delta$.
	Then, where $\cdot$ is one of $(+$, $-$, $*$, $/)$ we have that 
	$$f(z) \cdot g(z) = pz^\zeta + qz^\eta + o(z^\eta)$$
	$$\Leftrightarrow$$
	$$F \cdot G = p\epsilon^\zeta + q\epsilon^\eta$$
	Furthermore, for any analytic function $h:K \rightarrow K$ we have
	$$h(f(z)) = pz^\zeta + qz^\eta + o(z^\eta)$$ 
	$$\Leftrightarrow$$
	$$h(F) = p\epsilon^\zeta + q\epsilon^\eta$$
\end{proposition}

\section{Examples}

\subsection{Rational Polynomials at Infinity}
We can get a simple system for evaluating a rational polynomial in the infinite limit. For example, consider:
$$f(z) = \frac{z^3+z^2+1}{z^3+z}$$
Taking the Power Number $z = \epsilon^{-1}$. By the arithmetic described above we have:
$$\frac{(\epsilon^{-3})+(\epsilon^{-2})+1}{(\epsilon^{-3})+(\epsilon^{-1})} = \frac{\epsilon^{-3}}{\epsilon^{-3}}=\epsilon^0$$
Which gives the correct limit when considering $\epsilon \rightarrow 0$.


\section{Conclusion}


\end{document}
